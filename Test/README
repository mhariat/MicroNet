# Test [STEP 5]

Before beginning STEP 5, please be sure to have a directory named "quantized_weights" in "MicroNet/Quantization" in
which you would have put the checkpoint file of the previous quantization step (STEP 4).

For PyramidNet only, please respect the following syntax:

"Micronet/Quantization/quantized_weights/pyramidnet/pyramid_noskip_back/checkpoint_quantized_weights_[acc]_[compression]_[sparsity].pth"

The name of the pth file obtained at STEP 4 during quantization should already be in the format displayed just above.
The checkpoint file should only be put in the directory "Micronet/Quantization/quantized_weights/pyramidnet/pyramid_noskip_back".

For PyramidNet + SkipNet, please respect the following syntax:

"Micronet/Quantization/quantized_weights/pyramidskipnet/alpha_4/pyramid_skip_back/checkpoint_quantized_weights_[acc]_[compression]_[sparsity].pth"

The name of the pth file obtained at STEP 4 during quantization should already be in the format displayed just above. The
checkpoint file should only be put in the directory "Micronet/Quantization/quantized_weights/pyramidskipnet/alpha_4/pyramid_skip_back".


Still in the same docker than STEP 2-3-4 launch the command:

CUDA_VISIBLE_DEVICES=0 python /usr/share/bind_mount/scripts/MicroNet/Test/main.py --config_path /usr/share/bind_mount/scripts/MicroNet/Test/config.json

- Be sure to complete the json file "config.json" appropriately before pruning.

Here are the arguments that must be respected:

For PyramidNet only --> "exp_name": pyramidnet_noskip_back, "network": "pyramidnet"
For PyramidNet only --> "exp_name": pyramidnet_skip_back, "network": "pyramidskipnet"

You may want to change the batch_size.


In the case of PyramidNet only the arguments "checkpoint_file_sparsity" is the name of the checkpoint file located at :

"MicroNet/Sparsity/sparse_weights/pyramidnet/pyramid_noskip_back/checkpoint_run_[nb]_[acc]_[compression]_[sparsity].pth"


In the case of PyramidNet + SkipNet the arguments "checkpoint_file_sparsity" is the name of the checkpoint file located at :

"MicroNet/Sparsity/sparse_weights/pyramidskipnet/alpha_4/pyramid_skip_back/checkpoint_run_[nb]_[acc]_[compression]_[sparsity].pth"


The arguments "checkpoint_file_quantization" is the checkpoint file located at :

"MicroNet/Sparsity/sparse_weights/pyramidnet/pyramid_noskip_back/checkpoint_run_[nb]_[acc]_[compression]_[sparsity].pth"


In the case of PyramidNet only the arguments "checkpoint_file_quantization" is the name of the checkpoint file located at :

"Micronet/Quantization/quantized_weights/pyramidnet/pyramid_noskip_back/checkpoint_quantized_weights_[acc]_[compression]_[sparsity].pth"


In the case of PyramidNet + SkipNet the arguments "checkpoint_file_sparsity" is the name of the checkpoint file located at :

"Micronet/Quantization/quantized_weights/pyramidskipnet/alpha_4/pyramid_skip_back/checkpoint_quantized_weights_[acc]_[compression]_[sparsity].pth"


The "mul_bits" and "param_bits" arguments are the one found during the quantization at STEP 4 and corresponding respectively
to "activation_bits" and "weight_bits"

- Be sure to complete the json file "config.json" appropriately before applying the sparsity.



